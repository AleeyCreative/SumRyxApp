{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import string\n",
    "import operator\n",
    "import math\n",
    "import string\n",
    "from matplotlib import pyplot as plt\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.cluster import Birch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pikepdf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_clusters(X, labels):\n",
    "    \"\"\"\n",
    "    Takes in the datapoints and the cluster labels and then construcs a scatterplot indicatiing  each custer \n",
    "    \"\"\"\n",
    "    X = np.array(X)\n",
    "    plt.scatter(X[:,1], X[:,0], c=labels)\n",
    "    plt.show()\n",
    "    \n",
    "def viz_clusters_after(X, labels):\n",
    "    labels =list(set(X))\n",
    "    plt.plot(X[:,1], X[:,0], c=labels)\n",
    "    \n",
    "def draw_table(norm_X,mean,closest):\n",
    "    count = 0\n",
    "    sentences = []\n",
    "    for i in range(len(mean)):\n",
    "        sentences_with_label = [sent[1] for sent in norm_X if sent[0] == mean[i][0]]\n",
    "        for sent in sentences_with_label:\n",
    "            sentence_row = (count,sent,mean[i][0],mean[i][1],closest[i][1])\n",
    "            sentences.append(sentence_row)\n",
    "            count +=1\n",
    "    return np.array(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_threshold(sentences):\n",
    "    return int(0.5 * len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0  SENTENCE PREPROCESSING\n",
    "def preprocess(words):\n",
    "    stp = stopwords.words('english')\n",
    "    white_list = ['Allah', 'God']\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [lemmatize(word) for word in words]\n",
    "    words = [word for word in words if word not in stp]\n",
    "    words = [word for word in words if word not in string.punctuation]\n",
    "    return words\n",
    "\n",
    "def lemmatize(word):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmed = wnl.lemmatize(word)\n",
    "    return lemmed\n",
    "\n",
    "def tagger(sentence):\n",
    "    \"\"\"\n",
    "    takes a whole sentence as input and gets the Part-Of-Speech tag for each word in the sentence\n",
    "    \"\"\"\n",
    "    acceptable_words = []\n",
    "    word_tags = pos_tag(sentence)\n",
    "    print(word_tags)\n",
    "    for word_tag in word_tags:\n",
    "        if (word_tag[1] == \"NP\" or word_tag[1] == \"VP\"):\n",
    "            acceptable_words.append(word_tag[0])\n",
    "    return acceptable_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 CLUSTERING\n",
    "def vectorize(document):\n",
    "    words = word_tokenize(document)\n",
    "    words = preprocess(words)\n",
    "    X = [TaggedDocument(word,[idnx]) for idnx,word in enumerate(words)]\n",
    "    vectorizer = Doc2Vec(X, size=10)\n",
    "    sentence_vectors = [vectorizer.infer_vector(word_tokenize(sen), alpha=2,steps=400) for sen in sent_tokenize(document)]\n",
    "    return sentence_vectors\n",
    "\n",
    "def determine_th(document):\n",
    "    no_sen = len(sent_tokenize(document)) # the number of sentences in the document\n",
    "    if(no_sen <=50):\n",
    "        return 0.3\n",
    "    if(no_sen > 50 and no_sen <= 100):\n",
    "        return 0.5\n",
    "    if(n0_sen > 100  and no_sen <= 150):\n",
    "        return 0.7\n",
    "    if(no_sen > 150):\n",
    "        return 0.9\n",
    "    \n",
    "def calculate_mean(X):\n",
    "    clusters = set([sent[0] for sent in X ])\n",
    "    cluster_mean = []\n",
    "    for cluster in clusters:\n",
    "        cluster_value = 0\n",
    "        count = 0\n",
    "        for i,element in enumerate(X):\n",
    "            if (cluster == element[0]):\n",
    "                cluster_value += element[1]\n",
    "                count += 1\n",
    "        mean_cluster_value = cluster_value/count\n",
    "        cluster_mean.append([cluster,mean_cluster_value])\n",
    "    print(\"Cluster Means:\")\n",
    "    print(cluster_mean)\n",
    "    return cluster_mean\n",
    "\n",
    "def find_minimum_from_mean(cluster_means, vectorized):\n",
    "    \"\"\"\n",
    "    This function computes the minimal distance between each element in X and the elements in Y\n",
    "    cluster_means : A 2D array\n",
    "    points : A 2D array consisting of cluster type and the corresponding value\n",
    "\n",
    "    It returns an array which consist of point in X and the corresponding point in Y with the smallest distance the point in X\n",
    "\n",
    "    \"\"\"\n",
    "    minimal_distances = []\n",
    "    for clm in cluster_means:\n",
    "        points_in_cluster = [v[1] for v in vectorized if v[0] == clm[0]]\n",
    "        minimal = points_in_cluster[0]\n",
    "        for pt in points_in_cluster:\n",
    "            diff_current = abs(clm[1] - pt) \n",
    "            diff_minimal = clm[1] - minimal\n",
    "            if (diff_current < diff_minimal):\n",
    "                  minimal = pt\n",
    "        minimal_distances.append((clm[0],minimal))\n",
    "    print(\"Minimal\", minimal_distances)\n",
    "    return minimal_distances\n",
    "\n",
    "def normalize_vector(v, labels):\n",
    "    vectorized = []\n",
    "    for i in range(len(v)):\n",
    "        mean = abs(sum(v[i]/len(v[i])))\n",
    "        vectorized.append((labels[i],mean))\n",
    "    return vectorized\n",
    "\n",
    "def vectors_to_sentences(clustered_sentences, sentence_vector, sentences):\n",
    "    index = 0\n",
    "    selected_sentences = []\n",
    "    top_sentences = [s[1] for s in clustered_sentences ]\n",
    "    for v in sentence_vector:\n",
    "        if v[1] in top_sentences:\n",
    "            print(v[1])\n",
    "            selected_sentences.append((index,sentences[index]))\n",
    "        index +=1\n",
    "    return selected_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sentences(document):\n",
    "    X = vectorize(document)\n",
    "    th = determine_th(document)\n",
    "    bcl = Birch(branching_factor=10, n_clusters=None, threshold=th).fit(X) # the algorithm figures out the clusters\n",
    "    clusters = bcl.predict(X)\n",
    "    labels = bcl.labels_\n",
    "    norm_X = normalize_vector(X, labels)\n",
    "    viz_clusters(norm_X,labels) # visualization before finding the mean\n",
    "    cluster_means = calculate_mean(norm_X)\n",
    "    cluster_sentences = find_minimum_from_mean(cluster_means, norm_X)\n",
    "#     viz_clusters_after(cluster_sentences, set(labels)) # visualization after finding the closest to mean\n",
    "    sents = vectors_to_sentences(cluster_sentences, norm_X, sent_tokenize(document))\n",
    "    sentence_data = draw_table(norm_X,cluster_means,cluster_sentences)\n",
    "    sentence_data = pd.DataFrame(sentence_data, columns = ['Sentence', 'Vector_Value', ' Cluster_ID', 'Cluster_Mean', 'Closest_Sentence_Vector'])\n",
    "    return sents, sentence_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARIZE DOCUMENT \n",
    "def summarizeDocument(document):\n",
    "    \"\"\"\n",
    "    functions takes a document and returns its summary\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(document)\n",
    "    threshold = set_threshold(sent_tokenize(document))  \n",
    "    indexed_sentences, sentence_data = cluster_sentences(document) \n",
    "    summary = [sent[1] for sent in indexed_sentences]\n",
    "    return summary, sentence_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/.local/lib/python3.5/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
      "WARNING:gensim.models.doc2vec:Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Means:\n",
      "[[0, 0.027878005430102347], [1, 0.008751623741773074], [2, 0.01522156409919262], [3, 0.05900698900222778]]\n",
      "Minimal [(0, 0.0487155057489872), (1, 0.018661629619600717), (2, 0.01522156409919262), (3, 0.05900698900222778)]\n",
      "0.0487155057489872\n",
      "0.018661629619600717\n",
      "0.01522156409919262\n",
      "0.05900698900222778\n",
      "['Manually creating summaries can be a time-consuming activity.', 'When the volume of documents to be summarized becomes much, it becomes cumbersome to summarize these manually.', 'It also aims at producing summaries that covers the main ideas expressed in a passage.', 'Since documents are usually structured in such a way that different ideas are expressed at different sections (Rananavare & Reddy, 2017), the proposed system utilizes text clustering as a technique to handle this information spread as well reducing redundancy in the produced summaries by clustering sentences that most alike together and then picking a representative sentence from each cluster.']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Vector_Value</th>\n",
       "      <th>Cluster_ID</th>\n",
       "      <th>Cluster_Mean</th>\n",
       "      <th>Closest_Sentence_Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.048716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.048716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.048716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.048716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.048716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.018662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.015222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.059007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.059007</td>\n",
       "      <td>0.059007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence  Vector_Value   Cluster_ID  Cluster_Mean  Closest_Sentence_Vector\n",
       "0        0.0      0.048716          0.0      0.027878                 0.048716\n",
       "1        1.0      0.025898          0.0      0.027878                 0.048716\n",
       "2        2.0      0.027486          0.0      0.027878                 0.048716\n",
       "3        3.0      0.024390          0.0      0.027878                 0.048716\n",
       "4        4.0      0.012901          0.0      0.027878                 0.048716\n",
       "5        5.0      0.018662          1.0      0.008752                 0.018662\n",
       "6        6.0      0.004668          1.0      0.008752                 0.018662\n",
       "7        7.0      0.005015          1.0      0.008752                 0.018662\n",
       "8        8.0      0.012452          1.0      0.008752                 0.018662\n",
       "9        9.0      0.009845          1.0      0.008752                 0.018662\n",
       "10      10.0      0.001981          1.0      0.008752                 0.018662\n",
       "11      11.0      0.009670          1.0      0.008752                 0.018662\n",
       "12      12.0      0.007720          1.0      0.008752                 0.018662\n",
       "13      13.0      0.015222          2.0      0.015222                 0.015222\n",
       "14      14.0      0.059007          3.0      0.059007                 0.059007"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = open('./raw_text/test__3.txt').read()\n",
    "summary,sentence_data = summarizeDocument(document)\n",
    "print(summary)\n",
    "sentence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(doc,summary):\n",
    "    summ_stats = \"\"\"\n",
    "    No of Sentences : {no_sen}\n",
    "    No of Words : {no_words}\n",
    "    No of Characters : {no_char}\n",
    "    compression rate : {c_rate}%\n",
    "    \"\"\".format(no_sen = len(sent_tokenize(summary)), no_words = len(word_tokenize(summary)), no_char = len(summary), c_rate = (len(summary)/len(document) * 100 ))\n",
    "    return summ_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    No of Sentences : 4\\n    No of Words : 108\\n    No of Characters : 656\\n    compression rate : 27.903019991492982%\\n    '"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = open('./raw_text/summaries/by-sumryx/summary2.txt','w+')\n",
    "summary_text = \" \".join(summary) \n",
    "result.write(summary_text)\n",
    "summary_stats(document, summary_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokenize(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokenize(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2351"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
