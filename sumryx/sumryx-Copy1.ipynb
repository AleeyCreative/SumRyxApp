{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/.local/lib/python3.5/site-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing dependencies\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import string\n",
    "import operator\n",
    "import math\n",
    "import string\n",
    "from matplotlib import pyplot as plt\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.cluster import Birch\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pikepdf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_clusters(X, labels):\n",
    "    \"\"\"\n",
    "    Takes in the datapoints and the cluster labels and then construcs a scatterplot indicatiing  each custer \n",
    "    \"\"\"\n",
    "    X = np.array(X)\n",
    "    plt.scatter(X[:,1], X[:,0], c=labels)\n",
    "    plt.show()\n",
    "    \n",
    "def viz_clusters_after(X, labels):\n",
    "    labels =list(set(X))\n",
    "    plt.plot(X[:,1], X[:,0], c=labels)\n",
    "    \n",
    "def draw_table(norm_X,mean,closest):\n",
    "    count = 0\n",
    "    sentences = []\n",
    "    for i in range(len(mean)):\n",
    "        sentences_with_label = [sent[1] for sent in norm_X if sent[0] == mean[i][0]]\n",
    "        for sent in sentences_with_label:\n",
    "            sentence_row = (count,sent,mean[i][0],mean[i][1],closest[i][1])\n",
    "            sentences.append(sentence_row)\n",
    "            count +=1\n",
    "    return np.array(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_threshold(sentences):\n",
    "    return int(0.5 * len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0  SENTENCE PREPROCESSING\n",
    "def preprocess(words):\n",
    "    stp = stopwords.words('english')\n",
    "    white_list = ['Allah', 'God']\n",
    "    words = [word for word in words if word not in stp]\n",
    "    words = [word for word in words if word not in string.punctuation]\n",
    "    words = [word.lower() for word in words]\n",
    "    return words\n",
    "\n",
    "def lemmatize(sentence):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmed_words = []\n",
    "    for word in word_tokenize(sentence):\n",
    "        wrd = wnl.lemmatize(word)\n",
    "        lemmed_words.append(wrd)\n",
    "    return lemmed_words\n",
    "\n",
    "def tagger(sentence):\n",
    "    \"\"\"\n",
    "    takes a whole sentence as input and gets the Part-Of-Speech tag for each word in the sentence\n",
    "    \"\"\"\n",
    "    acceptable_words = []\n",
    "    word_tags = pos_tag(sentence)\n",
    "    print(word_tags)\n",
    "    for word_tag in word_tags:\n",
    "        if (word_tag[1] == \"NP\" or word_tag[1] == \"VP\"):\n",
    "            acceptable_words.append(word_tag[0])\n",
    "    return acceptable_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 CLUSTERING\n",
    "\n",
    "def cluster_sentences(document, sentences):\n",
    "    X = vectorize(document)\n",
    "    bcl = Birch(branching_factor=10, n_clusters=None, threshold=0.3).fit(X) # the algorithm figures out the clusters\n",
    "    clusters = bcl.predict(X)\n",
    "    labels = bcl.labels_\n",
    "    norm_X = normalize_vector(X, labels)\n",
    "    viz_clusters(norm_X,labels) # visualization before finding the mean\n",
    "    cluster_means = calculate_mean(norm_X)\n",
    "    cluster_sentences = find_minimum_from_mean(cluster_means, norm_X)\n",
    "#     viz_clusters_after(cluster_sentences, set(labels)) # visualization after finding the closest to mean\n",
    "    sents = vectors_to_sentences(cluster_sentences, norm_X, sentences)\n",
    "    sentence_data = draw_table(norm_X,cluster_means,cluster_sentences)\n",
    "    sentence_data = pd.DataFrame(sentence_data, columns = ['Sentence', 'Vector_Value', ' Cluster_ID', 'Cluster_Mean', 'Closest_Sentence_Vector'])\n",
    "    return sents, sentence_data\n",
    "\n",
    "def calculate_mean(X):\n",
    "    clusters = set([sent[0] for sent in X ])\n",
    "    cluster_mean = []\n",
    "    for cluster in clusters:\n",
    "        cluster_value = 0\n",
    "        count = 0\n",
    "        for i,element in enumerate(X):\n",
    "            if (cluster == element[0]):\n",
    "                cluster_value += element[1]\n",
    "                count += 1\n",
    "        mean_cluster_value = cluster_value/count\n",
    "        cluster_mean.append([cluster,mean_cluster_value])\n",
    "    print(\"Cluster Means:\")\n",
    "    print(cluster_mean)\n",
    "    return cluster_mean\n",
    "\n",
    "def find_minimum_from_mean(cluster_means, vectorized):\n",
    "    \"\"\"\n",
    "    This function computes the minimal distance between each element in X and the elements in Y\n",
    "    cluster_means : A 2D array\n",
    "    points : A 2D array consisting of cluster type and the corresponding value\n",
    "\n",
    "    It returns an array which consist of point in X and the corresponding point in Y with the smallest distance the point in X\n",
    "\n",
    "    \"\"\"\n",
    "    minimal_distances = []\n",
    "    for clm in cluster_means:\n",
    "        points_in_cluster = [v[1] for v in vectorized if v[0] == clm[0]]\n",
    "        minimal = points_in_cluster[0]\n",
    "        for pt in points_in_cluster:\n",
    "            diff_current = abs(clm[1] - pt) \n",
    "            diff_minimal = clm[1] - minimal\n",
    "            if (diff_current < diff_minimal):\n",
    "                  minimal = pt\n",
    "        minimal_distances.append((clm[0],minimal))\n",
    "    print(\"Minimal\", minimal_distances)\n",
    "    return minimal_distances\n",
    "\n",
    "def normalize_vector(v, labels):\n",
    "    vectorized = []\n",
    "    for i in range(len(v)):\n",
    "        mean = abs(sum(v[i]/len(v[i])))\n",
    "        vectorized.append((labels[i],mean))\n",
    "    return vectorized\n",
    "\n",
    "def vectors_to_sentences(clustered_sentences, sentence_vector, sentences):\n",
    "    print(\"Sentence Vectors == sentences\")\n",
    "    print(len(sentence_vector), len(sentences)) \n",
    "    index = 0\n",
    "    selected_sentences = []\n",
    "    top_sentences = [s[1] for s in clustered_sentences ]\n",
    "    for v in sentence_vector:\n",
    "        if v[1] in top_sentences:\n",
    "            print(v[1])\n",
    "            selected_sentences.append((index,sentences[index]))\n",
    "        index +=1\n",
    "    return selected_sentences\n",
    "\n",
    "def vectorize(document):\n",
    "    words = word_tokenize(document)\n",
    "    words = preprocess(words)\n",
    "    X = [TaggedDocument(word,[idnx]) for idnx,word in enumerate(words)]\n",
    "    vectorizer = Doc2Vec(X, size=10)\n",
    "    sentence_vectors = [vectorizer.infer_vector(word_tokenize(sen), alpha=2,steps=400) for sen in sent_tokenize(document)]\n",
    "    return sentence_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0 RANKING AND GENERATING THE FINAL SUMMARY\n",
    "def generate_summary(sentences,scores,threshold):\n",
    "        ranked_scores = sorted(scores, key=lambda sc:sc[1], reverse=True)\n",
    "        summary = []\n",
    "        for sent_rank in ranked_scores:\n",
    "            summary.append((sent_rank[0], sentences[sent_rank[0]]))\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARIZE DOCUMENT \n",
    "def summarizeDocument(document):\n",
    "    \"\"\"\n",
    "    functions takes a document and returns its summary\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(document)\n",
    "    threshold = set_threshold(sentences) \n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    indexed_sentences, sentence_data = cluster_sentences(document, sentences) \n",
    "    summary = [sentence[1] for sentence in indexed_sentences]\n",
    "    return summary, sentence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/.local/lib/python3.5/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Means:\n",
      "[[0, 0.5442608147859573], [1, 0.7635105145829064], [2, 0.6277379710227251], [3, 1.0456908997148275], [4, 0.6787973908441407], [5, 0.7025568783283234]]\n",
      "Minimal [(0, 0.5442608147859573), (1, 0.7738337591290474), (2, 0.6275933235883713), (3, 1.0456908997148275), (4, 0.683555856347084), (5, 0.7025568783283234)]\n",
      "Sentence Vectors == sentences\n",
      "42 42\n",
      "0.5442608147859573\n",
      "0.7738337591290474\n",
      "0.6275933235883713\n",
      "1.0456908997148275\n",
      "0.683555856347084\n",
      "0.7025568783283234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Text summarization is a branch of Natural Language Processing (NLP) which can be described as the process of creating a compressed representation of a text document which conveys the main ideas of the document (Tohalino & Amancio, 2017). Text summarization is an important field as the amount of textual data that different industries need to process keeps growing, (Bouscarrat, et al. Thus, text summarization as a tool, help in transforming these information in a smaller and easily digestible form. For a given document containing of a set of sentences S, the aim of extractive text summarization is to select top k sentences that covers the main idea expressed in that document (Nikolov, Pfieffer & Hahnloser, 2018). 1.3 Aim and Objectives of the Study\\nThe aim of the study to is build and evaluate a text summarization model utilizing both supervised and unsupervised techniques. Although the model used for summarization performs single document summarization, the entire system can generate summaries for multiple documents one at a time.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = open('./raw_text/test__1.txt').read()\n",
    "summary,sentence_data = summarizeDocument(document)\n",
    "\" \".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('./raw_text/summaries/summary1.txt', 'a')\n",
    "file.write(\"\".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function open in module io:\n",
      "\n",
      "open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)\n",
      "    Open file and return a stream.  Raise IOError upon failure.\n",
      "    \n",
      "    file is either a text or byte string giving the name (and the path\n",
      "    if the file isn't in the current working directory) of the file to\n",
      "    be opened or an integer file descriptor of the file to be\n",
      "    wrapped. (If a file descriptor is given, it is closed when the\n",
      "    returned I/O object is closed, unless closefd is set to False.)\n",
      "    \n",
      "    mode is an optional string that specifies the mode in which the file\n",
      "    is opened. It defaults to 'r' which means open for reading in text\n",
      "    mode.  Other common values are 'w' for writing (truncating the file if\n",
      "    it already exists), 'x' for creating and writing to a new file, and\n",
      "    'a' for appending (which on some Unix systems, means that all writes\n",
      "    append to the end of the file regardless of the current seek position).\n",
      "    In text mode, if encoding is not specified the encoding used is platform\n",
      "    dependent: locale.getpreferredencoding(False) is called to get the\n",
      "    current locale encoding. (For reading and writing raw bytes use binary\n",
      "    mode and leave encoding unspecified.) The available modes are:\n",
      "    \n",
      "    ========= ===============================================================\n",
      "    Character Meaning\n",
      "    --------- ---------------------------------------------------------------\n",
      "    'r'       open for reading (default)\n",
      "    'w'       open for writing, truncating the file first\n",
      "    'x'       create a new file and open it for writing\n",
      "    'a'       open for writing, appending to the end of the file if it exists\n",
      "    'b'       binary mode\n",
      "    't'       text mode (default)\n",
      "    '+'       open a disk file for updating (reading and writing)\n",
      "    'U'       universal newline mode (deprecated)\n",
      "    ========= ===============================================================\n",
      "    \n",
      "    The default mode is 'rt' (open for reading text). For binary random\n",
      "    access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n",
      "    'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n",
      "    raises an `FileExistsError` if the file already exists.\n",
      "    \n",
      "    Python distinguishes between files opened in binary and text modes,\n",
      "    even when the underlying operating system doesn't. Files opened in\n",
      "    binary mode (appending 'b' to the mode argument) return contents as\n",
      "    bytes objects without any decoding. In text mode (the default, or when\n",
      "    't' is appended to the mode argument), the contents of the file are\n",
      "    returned as strings, the bytes having been first decoded using a\n",
      "    platform-dependent encoding or using the specified encoding if given.\n",
      "    \n",
      "    'U' mode is deprecated and will raise an exception in future versions\n",
      "    of Python.  It has no effect in Python 3.  Use newline to control\n",
      "    universal newlines mode.\n",
      "    \n",
      "    buffering is an optional integer used to set the buffering policy.\n",
      "    Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n",
      "    line buffering (only usable in text mode), and an integer > 1 to indicate\n",
      "    the size of a fixed-size chunk buffer.  When no buffering argument is\n",
      "    given, the default buffering policy works as follows:\n",
      "    \n",
      "    * Binary files are buffered in fixed-size chunks; the size of the buffer\n",
      "      is chosen using a heuristic trying to determine the underlying device's\n",
      "      \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n",
      "      On many systems, the buffer will typically be 4096 or 8192 bytes long.\n",
      "    \n",
      "    * \"Interactive\" text files (files for which isatty() returns True)\n",
      "      use line buffering.  Other text files use the policy described above\n",
      "      for binary files.\n",
      "    \n",
      "    encoding is the name of the encoding used to decode or encode the\n",
      "    file. This should only be used in text mode. The default encoding is\n",
      "    platform dependent, but any encoding supported by Python can be\n",
      "    passed.  See the codecs module for the list of supported encodings.\n",
      "    \n",
      "    errors is an optional string that specifies how encoding errors are to\n",
      "    be handled---this argument should not be used in binary mode. Pass\n",
      "    'strict' to raise a ValueError exception if there is an encoding error\n",
      "    (the default of None has the same effect), or pass 'ignore' to ignore\n",
      "    errors. (Note that ignoring encoding errors can lead to data loss.)\n",
      "    See the documentation for codecs.register or run 'help(codecs.Codec)'\n",
      "    for a list of the permitted encoding error strings.\n",
      "    \n",
      "    newline controls how universal newlines works (it only applies to text\n",
      "    mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It works as\n",
      "    follows:\n",
      "    \n",
      "    * On input, if newline is None, universal newlines mode is\n",
      "      enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
      "      these are translated into '\\n' before being returned to the\n",
      "      caller. If it is '', universal newline mode is enabled, but line\n",
      "      endings are returned to the caller untranslated. If it has any of\n",
      "      the other legal values, input lines are only terminated by the given\n",
      "      string, and the line ending is returned to the caller untranslated.\n",
      "    \n",
      "    * On output, if newline is None, any '\\n' characters written are\n",
      "      translated to the system default line separator, os.linesep. If\n",
      "      newline is '' or '\\n', no translation takes place. If newline is any\n",
      "      of the other legal values, any '\\n' characters written are translated\n",
      "      to the given string.\n",
      "    \n",
      "    If closefd is False, the underlying file descriptor will be kept open\n",
      "    when the file is closed. This does not work when a file name is given\n",
      "    and must be True in that case.\n",
      "    \n",
      "    A custom opener can be used by passing a callable as *opener*. The\n",
      "    underlying file descriptor for the file object is then obtained by\n",
      "    calling *opener* with (*file*, *flags*). *opener* must return an open\n",
      "    file descriptor (passing os.open as *opener* results in functionality\n",
      "    similar to passing None).\n",
      "    \n",
      "    open() returns a file object whose type depends on the mode, and\n",
      "    through which the standard file operations such as reading and writing\n",
      "    are performed. When open() is used to open a file in a text mode ('w',\n",
      "    'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n",
      "    a file in a binary mode, the returned class varies: in read binary\n",
      "    mode, it returns a BufferedReader; in write binary and append binary\n",
      "    modes, it returns a BufferedWriter, and in read/write mode, it returns\n",
      "    a BufferedRandom.\n",
      "    \n",
      "    It is also possible to use a string or bytearray as a file for both\n",
      "    reading and writing. For strings StringIO can be used like a file\n",
      "    opened in a text mode, and for bytes a BytesIO can be used like a file\n",
      "    opened in a binary mode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
